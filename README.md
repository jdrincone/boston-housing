# Boston Housing Price Prediction API

Pipeline **MLOps end-to-end** para entrenar y desplegar un modelo de **regresiÃ³n** sobre el dataset de **Boston Housing**. Incluye versionado de datos con **DVC**, entrenamiento reproducible con **AutoML (FLAML)**, artefactos versionados y una **API** en **FastAPI** lista para producciÃ³n con base de datos PostgreSQL.

---

## ğŸ“‹ Tabla de Contenidos

- [âš™ï¸ Prerrequisitos](#ï¸-prerrequisitos)
- [ğŸš€ Inicio RÃ¡pido](#-inicio-rÃ¡pido)
- [ğŸ—ï¸ Arquitectura del Proyecto](#ï¸-arquitectura-del-proyecto)
- [ğŸ“Š VisualizaciÃ³n del Pipeline](#-visualizaciÃ³n-del-pipeline)
- [ğŸ§  Entrenamiento del Modelo](#-entrenamiento-del-modelo)
- [ğŸ”Œ Uso de la API](#-uso-de-la-api)
- [ğŸ“Š Monitoreo y EvaluaciÃ³n](#-monitoreo-y-evaluaciÃ³n)
- [ğŸ”„ CI/CD y AutomatizaciÃ³n](#-cicd-y-automatizaciÃ³n)
- [ğŸ§ª Testing](#-testing)
- [ğŸ“ˆ CaracterÃ­sticas del Modelo](#-caracterÃ­sticas-del-modelo)
- [ğŸ“ˆ PresentaciÃ³n PDF-Explicativa](#-PresentaciÃ³n PDF-Explicativa)
- [uso de herramientas AI](#-uso de herramientas AI)

---

## âš™ï¸ Prerrequisitos

### Software Requerido
- **Python 3.11+**
- **Git**
- **Docker & Docker Compose**
- **`uv`** â†’ `pip install uv`

### Verificar InstalaciÃ³n
```bash
# Instalar uv si no lo tienes
pip install uv

# Verificar versiones
python --version  # Debe ser 3.11+
docker --version
docker-compose --version
```

---

## ğŸš€ Inicio RÃ¡pido

### 1. Clonar y Preparar
```bash
# Clonar el repositorio
git clone https://github.com/jdrincone/boston-housing.git
cd boston-housing

# Crear entorno virtual e instalar dependencias
uv venv
source .venv/bin/activate  # Linux/macOS
# .venv\Scripts\activate   # Windows
uv pip install -r requirements.txt
```

### 2. Entrenar el Modelo
```bash
# Descargar datos y entrenar modelo
dvc pull
dvc repro
```

### 3. Desplegar con Docker
```bash
# Levantar todos los servicios
docker-compose up --build
```

### 4. Probar la API
```bash
# Health check
curl http://localhost:8000/

# Realizar predicciÃ³n
curl -X POST "http://localhost:8000/predict" \
     -H "Content-Type: application/json" \
     -d '{
       "CRIM": 0.02731,
       "ZN": 0.0,
       "INDUS": 7.07,
       "CHAS": 0,
       "NOX": 0.469,
       "RM": 6.421,
       "AGE": 78.9,
       "DIS": 4.9671,
       "RAD": 2,
       "TAX": 242,
       "PTRATIO": 17.8,
       "B": 396.9,
       "LSTAT": 9.14
     }'
```

**Servicios disponibles:**
- ğŸŒ **API**: http://localhost:8000
- ğŸ“š **DocumentaciÃ³n**: http://localhost:8000/docs
- ğŸ—„ï¸ **Base de datos**: localhost:5432

---

## ğŸ—ï¸ Arquitectura del Proyecto

```
boston-housing/
â”œâ”€â”€ app/                          # ğŸŒ API FastAPI
â”‚   â”œâ”€â”€ main.py                   # Endpoints principales
â”‚   â”œâ”€â”€ schemas.py                # ValidaciÃ³n Pydantic
â”‚   â””â”€â”€ database.py               # ConfiguraciÃ³n PostgreSQL
â”œâ”€â”€ src/                          # ğŸ¤– Pipeline de ML
â”‚   â”œâ”€â”€ config.py                 # ConfiguraciÃ³n y rutas
â”‚   â”œâ”€â”€ data_manager.py           # I/O de modelos y mÃ©tricas
â”‚   â”œâ”€â”€ pipeline.py               # Pipeline ML con FLAML
â”‚   â””â”€â”€ train.py                  # Script de entrenamiento
â”œâ”€â”€ scripts/                      # ğŸ“œ Scripts de utilidad
â”‚   â”œâ”€â”€ prepare_data.py           # DivisiÃ³n train/backtest
â”‚   â””â”€â”€ backtesting.py            # EvaluaciÃ³n del modelo
â”œâ”€â”€ data/                         # ğŸ“Š Datos (DVC tracked)
â”‚   â”œâ”€â”€ HousingData.csv           # Dataset original
â”‚   â”œâ”€â”€ train_data.csv            # Datos de entrenamiento
â”‚   â””â”€â”€ backtest_data.csv         # Datos de backtesting
â”œâ”€â”€ docs/                         # ğŸ“Š Documentos Explicativos y DiagramaciÃ³n
â”‚   â”œâ”€â”€ boston_housing_presentation.pdf           
    ....

â”œâ”€â”€ models/                       # ğŸ¯ Modelos (DVC tracked)
â”‚   â””â”€â”€ best_pipeline.pkl         # Pipeline completo serializado
â”œâ”€â”€ reports/                      # ğŸ“ˆ Reportes (DVC tracked)
â”‚   â”œâ”€â”€ metrics.json              # MÃ©tricas del modelo
â”‚   â”œâ”€â”€ shap_summary.png          # AnÃ¡lisis SHAP
â”‚   â”œâ”€â”€ feature_importance.png    # Importancia de features
â”‚   â”œâ”€â”€ automl_summary.txt        # Resumen de AutoML
â”‚   â”œâ”€â”€ main.log                  # Logs de entrenamiento
â”‚   â”œâ”€â”€ drift.html                # Reporte de Drift
â”‚   â””â”€â”€ backtest_report.csv       # Resultado de Backtesting
â”œâ”€â”€ tests/                        # ğŸ§ª Tests unitarios
â”‚   â”œâ”€â”€ test_api.py               # Tests de la API
â”‚   â””â”€â”€ test_training.py          # Tests del pipeline
â”œâ”€â”€ .github/workflows/            # ğŸ”„ CI/CD
â”‚   â”œâ”€â”€ ci.yml                    # Pipeline de CI
â”‚   â””â”€â”€ retrain_model.yml         # Reentreno automÃ¡tico
â”œâ”€â”€ docs/                         # ğŸ“š DocumentaciÃ³n
â”‚   â””â”€â”€ HousingData-*.svg         # Diagramas del pipeline
â”œâ”€â”€ dvc.yaml                      # ConfiguraciÃ³n DVC
â”œâ”€â”€ params.yaml                   # ParÃ¡metros del modelo
â”œâ”€â”€ docker-compose.yml            # OrquestaciÃ³n de servicios
â”œâ”€â”€ Dockerfile                    # Imagen de la API
â””â”€â”€ requirements.txt              # Dependencias Python
```

---

## ğŸ“Š VisualizaciÃ³n del Pipeline

![Pipeline de Datos](docs/HousingData-2025-10-10-041429.svg)

### Monitoreo de Drift
![Monitoreo Drift](docs/drift.png)
[Ver Informe Completo](reports/drift.html)

---

## ğŸ§  Entrenamiento del Modelo

### Comandos BÃ¡sicos
```bash
# Descargar datos
dvc pull

# Ejecutar pipeline completo
dvc repro

# Ver el grafo del pipeline
dvc dag

# Reentreno forzado
dvc repro --force
```

### Artefactos Generados
- âœ… **Modelo**: `models/best_pipeline.pkl`
- âœ… **MÃ©tricas**: `reports/metrics.json`
- âœ… **Reportes**: SHAP plots, feature importance
- âœ… **Logs**: `reports/main.log`

---

## ğŸ”Œ Uso de la API

### Health Check
```bash
curl http://localhost:8000/
```

**Respuesta:**
```json
{
  "status": "ok",
  "message": "API is running!"
}
```

### Realizar PredicciÃ³n
```bash
curl -X POST "http://localhost:8000/predict" \
     -H "Content-Type: application/json" \
     -d '{
       "CRIM": 0.02731,
       "ZN": 0.0,
       "INDUS": 7.07,
       "CHAS": 0,
       "NOX": 0.469,
       "RM": 6.421,
       "AGE": 78.9,
       "DIS": 4.9671,
       "RAD": 2,
       "TAX": 242,
       "PTRATIO": 17.8,
       "B": 396.9,
       "LSTAT": 9.14
     }'
```

**Respuesta:**
```json
{
  "prediction": 24.5
}
```

### DocumentaciÃ³n Interactiva
Visita http://localhost:8000/docs para la documentaciÃ³n interactiva de la API.

---

## ğŸ“Š Monitoreo y EvaluaciÃ³n

### Backtesting del Modelo
```bash
# AsegÃºrate de que la API estÃ© corriendo
docker-compose up --build

# En otra terminal, ejecuta el backtesting
python -m scripts.backtesting
```

**Archivos generados:**
- `reports/backtest_report.csv` - Predicciones vs valores reales
- `reports/backtest.log` - Logs del proceso

### MÃ©tricas Disponibles
- **Logs de entrenamiento**: `reports/main.log`
- **MÃ©tricas del modelo**: `reports/metrics.json`
- **AnÃ¡lisis SHAP**: `reports/shap_summary.png`
- **Importancia de features**: `reports/feature_importance.png`
- **Resumen AutoML**: `reports/automl_summary.txt`

---

## ğŸ”„ CI/CD y AutomatizaciÃ³n

### Pipeline de CI/CD
El proyecto incluye automatizaciÃ³n completa con GitHub Actions:

#### **CI Pipeline** (`.github/workflows/ci.yml`)
- âœ… **Triggers**: Push a `main`/`develop`, PRs a `main`
- âœ… **Validaciones**: Linting (Ruff), Tests (pytest), DVC
- âœ… **Servicios**: PostgreSQL 13 con health checks

#### **Reentreno AutomÃ¡tico** (`.github/workflows/retrain_model.yml`)
- âœ… **Triggers**: Manual + cada 3 dÃ­as a las 02:00 UTC
- âœ… **Proceso**: Reentreno completo + push de artefactos
- âœ… **Monitoreo**: Logs detallados en GitHub Actions

### ConfiguraciÃ³n de Secrets 
## (SOLO SI SE DESEA TRACKAR LOS ARTEFACTOS EN UN REPO REMOTO/ DE LO CONTRARIO ESTOS QUEDAN EN LOCAL EN .dvc/cache)
## Completamente agnostico a una nube
Configura en GitHub Settings â†’ Secrets and variables â†’ Actions:
- `AWS_ACCESS_KEY_ID`
- `AWS_SECRET_ACCESS_KEY`

---

## ğŸ§ª Testing

```bash
# Ejecutar todos los tests
pytest

# Tests especÃ­ficos
pytest tests/test_api.py
pytest tests/test_training.py

```

---

## ğŸ“ˆ CaracterÃ­sticas del Modelo

### Features Utilizadas (13 variables)
| Feature | DescripciÃ³n |
|---------|-------------|
| **CRIM** | Tasa de criminalidad per cÃ¡pita |
| **ZN** | ProporciÃ³n de terreno residencial zonificado |
| **INDUS** | ProporciÃ³n de acres de negocio no minorista |
| **CHAS** | Variable dummy del rÃ­o Charles |
| **NOX** | ConcentraciÃ³n de Ã³xidos nÃ­tricos |
| **RM** | NÃºmero promedio de habitaciones por vivienda |
| **AGE** | ProporciÃ³n de unidades ocupadas construidas antes de 1940 |
| **DIS** | Distancias ponderadas a cinco centros de empleo de Boston |
| **RAD** | Ãndice de accesibilidad a autopistas radiales |
| **TAX** | Tasa de impuesto a la propiedad |
| **PTRATIO** | Ratio alumno-profesor por ciudad |
| **B** | ProporciÃ³n de afroamericanos por ciudad |
| **LSTAT** | % de estatus socioeconÃ³mico bajo |

### Pipeline de ML
1. **ImputaciÃ³n**: Valores faltantes con mediana
2. **Escalado**: StandardScaler
3. **AutoML**: FLAML con bÃºsqueda automÃ¡tica de hiperparÃ¡metros
4. **MÃ©tricas**: RÂ², MSE, RMSE, MAE
5. **Explicabilidad**: SHAP y feature importance

### TecnologÃ­as
- **API**: FastAPI + Uvicorn
- **Base de datos**: PostgreSQL + SQLAlchemy
- **ContenerizaciÃ³n**: Docker + Docker Compose
- **Versionado**: Git + DVC
- **GestiÃ³n de entorno**: `uv`
- **Modelado**: scikit-learn, FLAML (AutoML), SHAP, XGBoost
- **Testing**: pytest + httpx
- **Linting**: ruff

---



# Verifica que el modelo existe
ls -la models/best_pipeline.pkl
```

```bash
# 1. Verifica que el modelo estÃ© entrenado
ls -la models/best_pipeline.pkl

# 2. Si no existe, entrena el modelo
dvc repro

# 3. Reinicia la API
docker-compose restart api
```
```

```bash
# Configura el remoto DVC
dvc remote add -d myremote s3://tu-bucket
dvc remote modify myremote access_key_id TU_ACCESS_KEY
dvc remote modify myremote secret_access_key TU_SECRET_KEY
```

## Herramientas de IA usadas (breve)

* **Mermaid (mermaidchart)**: para **diagramar** la arquitectura, el pipeline (DVC) y los flujos de predicciÃ³n/serving de forma rÃ¡pida y editable en texto.
* **Cursor**: asistente de cÃ³digo y redacciÃ³n tÃ©cnica para **borradores de README y documentaciÃ³n**. Ãštil para iterar rÃ¡pido, aunque **siempre validando y corrigiendo** lo que sugiere (evita â€œinventosâ€).
* **Gemini**: apoyo para **estructurar el flujo en DVC** (stages, dependencias y artefactos), proponiendo esquemas que luego se ajustaron al contexto real del repo.

**ConclusiÃ³n:** estas herramientas no sustituyen la verificaciÃ³n tÃ©cnica, pero son una **gran ayuda para aterrizar ideas y prototipos con velocidad**, reduciendo tiempo en primeras versiones de diagramas, documentaciÃ³n y estructura del pipeline.
